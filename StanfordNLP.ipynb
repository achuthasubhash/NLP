{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://analyticsindiamag.com/hands-on-guide-to-stanfordnlp-a-python-wrapper-for-popular-nlp-library-corenlp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default treebank \"en_ewt\" for language \"en\".\n",
      "Would you like to download the models for: en_ewt now? (Y/n)\n",
      "y\n",
      "\n",
      "Default download directory: C:\\Users\\DELL\\stanfordnlp_resources\n",
      "Hit enter to continue or type an alternate directory.\n",
      "\n",
      "\n",
      "Downloading models for: en_ewt\n",
      "Download location: C:\\Users\\DELL\\stanfordnlp_resources\\en_ewt_models.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 235M/235M [02:55<00:00, 1.34MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete.  Models saved to: C:\\Users\\DELL\\stanfordnlp_resources\\en_ewt_models.zip\n",
      "Extracting models file for: en_ewt\n",
      "Cleaning up...Done.\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp as st\n",
    "\n",
    "st.download('en')      #Downloading the English Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\DELL\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\DELL\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tagger.pt', 'pretrain_path': 'C:\\\\Users\\\\DELL\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\DELL\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\DELL\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_parser.pt', 'pretrain_path': 'C:\\\\Users\\\\DELL\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "pipe = st.Pipeline()\n",
    "\n",
    "text = pipe(\"This artcile will tell you How to use StanfordNLP. Let us start.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This', '2', 'det')\n",
      "('artcile', '4', 'nsubj')\n",
      "('will', '4', 'aux')\n",
      "('tell', '0', 'root')\n",
      "('you', '4', 'obj')\n",
      "('How', '8', 'advmod')\n",
      "('to', '8', 'mark')\n",
      "('use', '4', 'ccomp')\n",
      "('Stanford', '10', 'compound')\n",
      "('NLP', '8', 'obj')\n",
      "('.', '4', 'punct')\n"
     ]
    }
   ],
   "source": [
    "text.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Token index=1;words=[<Word index=1;text=Let;lemma=let;upos=VERB;xpos=VB;feats=Mood=Imp|VerbForm=Fin;governor=0;dependency_relation=root>]>\n",
      "<Token index=2;words=[<Word index=2;text=us;lemma=we;upos=PRON;xpos=PRP;feats=Case=Acc|Number=Plur|Person=1|PronType=Prs;governor=1;dependency_relation=obj>]>\n",
      "<Token index=3;words=[<Word index=3;text=start;lemma=start;upos=VERB;xpos=VB;feats=VerbForm=Inf;governor=1;dependency_relation=xcomp>]>\n",
      "<Token index=4;words=[<Word index=4;text=.;lemma=.;upos=PUNCT;xpos=.;feats=_;governor=1;dependency_relation=punct>]>\n"
     ]
    }
   ],
   "source": [
    "text.sentences[1].print_tokens() #Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "artcile\n",
      "will\n",
      "tell\n",
      "you\n",
      "how\n",
      "to\n",
      "use\n",
      "Stanford\n",
      "NLP\n",
      ".\n",
      "let\n",
      "we\n",
      "start\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in text.sentences: #Lemmatization\n",
    "    for j in i.words:\n",
    "        print(j.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "NN\n",
      "MD\n",
      "VB\n",
      "PRP\n",
      "WRB\n",
      "TO\n",
      "VB\n",
      "NNP\n",
      "NNP\n",
      ".\n",
      "VB\n",
      "PRP\n",
      "VB\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in text.sentences: #POS Tagging\n",
    "    for j in i.words:\n",
    "        print(j.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 det\n",
      "4 nsubj\n",
      "4 aux\n",
      "0 root\n",
      "4 obj\n",
      "8 advmod\n",
      "8 mark\n",
      "4 ccomp\n",
      "10 compound\n",
      "8 obj\n",
      "4 punct\n",
      "0 root\n",
      "1 obj\n",
      "1 xcomp\n",
      "1 punct\n"
     ]
    }
   ],
   "source": [
    "for i in text.sentences: #Deparsing\n",
    "    for j in i.words:\n",
    "        print(j.governor, j.dependency_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StanfordNLP supports around 53 languages and we can download the models for different languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
