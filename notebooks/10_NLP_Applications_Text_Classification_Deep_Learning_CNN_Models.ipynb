{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f64bBXyhpxTR"
   },
   "source": [
    "# Text Classification - Deep Learning CNN Models\n",
    "\n",
    "<img src=\"https://github.com/dipanjanS/nlp_workshop_dhs18/blob/master/Unit%2012%20-%20Project%209%20-%20Sentiment%20Analysis%20-%20Supervised%20Learning/banner.jpeg?raw=1\">\n",
    "\n",
    "When it comes to text data, sentiment analysis is one of the most widely performed analysis on it. Sentiment Analysis has been through tremendous improvements from the days of classic methods to recent times where in the state of the art models utilize deep learning to improve the performance.\n",
    "\n",
    "Convolutional Neural Networks or CNNs are the work-horse of the deep learning world. They have, in some sense, brought deep learning research into mainstream discussions. The advancements in the image classification world has left even humans behind.\n",
    "\n",
    "<img src=\"https://github.com/dipanjanS/nlp_workshop_dhs18/blob/master/Unit%2012%20-%20Project%209%20-%20Sentiment%20Analysis%20-%20Supervised%20Learning/cnn.png?raw=1\">\n",
    "In this project, we will attempt at performing sentiment analysis utilizing the power of CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "id": "iayiP3GZrjjk",
    "outputId": "0156a404-33b7-4e53-ec9c-a28ab019732e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading https://files.pythonhosted.org/packages/85/41/c3dfd5feb91a8d587ed1a59f553f07c05f95ad4e5d00ab78702fbf8fe48a/contractions-0.0.24-py2.py3-none-any.whl\n",
      "Collecting textsearch\n",
      "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
      "Collecting pyahocorasick\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 12.3MB/s \n",
      "\u001b[?25hCollecting Unidecode\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 22.0MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81692 sha256=f01a1dfd242fadf9ac9f5c58e0da5f43b45df82f1e6d24d37eaf0c773b772564\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: pyahocorasick, Unidecode, textsearch, contractions\n",
      "Successfully installed Unidecode-1.1.1 contractions-0.0.24 pyahocorasick-1.4.0 textsearch-0.0.17\n",
      "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (0.0.17)\n",
      "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.1.1)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.4.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install contractions\n",
    "!pip install textsearch\n",
    "!pip install tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gbnh0egkUzRX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_JEXODppxTc"
   },
   "source": [
    "## Load Movie Review Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "U7pQ5WR1VYqm",
    "outputId": "768b6838-021e-4d9d-eb59-93e94f205384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2011%20-%20Sentiment%20Analysis%20-%20Unsupervised%20Learning/movie_reviews.csv.bz2', compression='bz2')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "XMP7r5cUV6-B",
    "outputId": "c3aa795d-e09c-43ad-fb70-da185b4e997b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek at the data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-qBM4Od_pxTp"
   },
   "source": [
    "### Prepare Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XpwueLn6V-qF"
   },
   "outputs": [],
   "source": [
    "# build train and test datasets\n",
    "reviews = dataset['review'].values\n",
    "sentiments = dataset['sentiment'].values\n",
    "\n",
    "train_reviews = reviews[:35000]\n",
    "train_sentiments = sentiments[:35000]\n",
    "\n",
    "test_reviews = reviews[35000:]\n",
    "test_sentiments = sentiments[35000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CETaiGM2tO_d"
   },
   "source": [
    "# Text Wrangling & Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkFyu9u3tUOi"
   },
   "outputs": [],
   "source": [
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "import tqdm\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def strip_html_tags(text):\n",
    "  soup = BeautifulSoup(text, \"html.parser\")\n",
    "  [s.extract() for s in soup(['iframe', 'script'])]\n",
    "  stripped_text = soup.get_text()\n",
    "  stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "  return stripped_text\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "  return text\n",
    "\n",
    "def pre_process_corpus(docs):\n",
    "  norm_docs = []\n",
    "  for doc in tqdm.tqdm(docs):\n",
    "    doc = strip_html_tags(doc)\n",
    "    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "    doc = doc.lower()\n",
    "    doc = remove_accented_chars(doc)\n",
    "    doc = contractions.fix(doc)\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = re.sub(' +', ' ', doc)\n",
    "    doc = doc.strip()  \n",
    "    norm_docs.append(doc)\n",
    "  \n",
    "  return norm_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "EgAqgSnHtap5",
    "outputId": "388af7f0-bd24-4829-8554-4b02f9cb5108"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35000/35000 [00:14<00:00, 2412.80it/s]\n",
      "100%|██████████| 15000/15000 [00:06<00:00, 2402.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.6 s, sys: 112 ms, total: 20.8 s\n",
      "Wall time: 20.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "norm_train_reviews = pre_process_corpus(train_reviews)\n",
    "norm_test_reviews = pre_process_corpus(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COgKPRmLpxTu"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "To prepare text data for our deep learning model, we transform each review into a sequence.\n",
    "Every word in the review is mapped to an integer index and thus the sentence turns into a sequence of numbers.\n",
    "\n",
    "To perform this transformation, keras provides the ```Tokenizer```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dff8sG63cw03"
   },
   "outputs": [],
   "source": [
    "t = Tokenizer(oov_token='<UNK>')\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(norm_train_reviews)\n",
    "t.word_index['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0xd_eGZ1vQRR",
    "outputId": "7c0b2b5d-43f0-4757-a9d0-5426b3de01c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('dawgis', 175859), ('<PAD>', 0), 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), min([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), t.word_index['<UNK>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4yv_m8T5c2xg"
   },
   "outputs": [],
   "source": [
    "train_sequences = t.texts_to_sequences(norm_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifZCCxtydEnc"
   },
   "outputs": [],
   "source": [
    "test_sequences = t.texts_to_sequences(norm_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "ldkDHyjZgaFV",
    "outputId": "0ee278a3-b63f-4d1a-9a25-21faca939cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size=175860\n",
      "Number of Documents=35000\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size={}\".format(len(t.word_index)))\n",
    "print(\"Number of Documents={}\".format(t.document_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "CQjiXA7Ntw13",
    "outputId": "c70b1f93-c18a-4661-cac5-e9d2c709d54c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_lens = [len(s) for s in train_sequences]\n",
    "test_lens = [len(s) for s in test_sequences]\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "h1 = ax[0].hist(train_lens)\n",
    "h2 = ax[1].hist(test_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xfZwP6C8pxT8"
   },
   "source": [
    "### Sequence Normalization\n",
    "\n",
    "Not all reviews are of same length. To handle this difference in length of reviews, we define a maximum length.\n",
    "For reviews which are smaller than this length, we pad them with zeros which longer ones are truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BtuGJ0wXjQnC"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wAnv99kzWA5k",
    "outputId": "5664d25d-f09f-4c8c-a745-e2d8d6bf2dec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 1000), (15000, 1000))"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad dataset to a maximum review length in words\n",
    "X_train = sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test = sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9X_4ticSpxUC"
   },
   "source": [
    "### Encoding Labels\n",
    "\n",
    "The dataset contains labels of the form positive/negative. The following step encodes the labels using ```sklearn's``` ```LabelEncoder```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRMaWb1ldqyl"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "num_classes=2 # positive -> 1, negative -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJjbtyDjfsd1"
   },
   "outputs": [],
   "source": [
    "y_train = le.fit_transform(train_sentiments)\n",
    "y_test = le.transform(test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iaqFz7ZpdoLC"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCjRYBh2pxUM"
   },
   "source": [
    "# Prepare the Model\n",
    "\n",
    "Since textual data is a sequence of words, we utilize ```1D``` convolutions to scan through the sentences.\n",
    "The model first transforms each word into lower dimensional embedding/vector space followed by 1d convolutions and then passing the data through dense layers before the final layer for classification\n",
    "\n",
    "## Embeddings\n",
    "\n",
    "The Embedding layer helps us generate the word embeddings from scratch. This layer\n",
    "is also initialized with some weights and is updated based on our optimizer, similar to\n",
    "weights on the neuron units in other layers when the network tries to minimize the loss\n",
    "in each epoch. Thus, the embedding layer tries to optimize its weights such that we get\n",
    "the best word embeddings that will generate minimum error in the model and capture\n",
    "semantic similarity and relationships among words. How do we get the embeddings?\n",
    "Let’s say we have a review with three terms ['movie', 'was', 'good'] and a vocab_map\n",
    "consisting of word to index mappings for 175860 words. \n",
    "\n",
    "![](https://i.imgur.com/WuV47DW.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LR3mdd8kjgW1"
   },
   "outputs": [],
   "source": [
    "EMBED_SIZE = 300\n",
    "EPOCHS=10\n",
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "AXhAERVeXhmZ",
    "outputId": "c16982e1-aa7d-4586-80d2-4e31857a3652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1000, 300)         52758000  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1000, 128)         153728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 64)           32832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 250, 32)           8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 125, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1024256   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 53,977,297\n",
      "Trainable params: 53,977,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE, EMBED_SIZE, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Conv1D(filters=128, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szNl8QiQpxUa"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "0uc0jXszf5ob",
    "outputId": "08ff379f-3ac4-4982-d614-35e5a846113c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "247/247 [==============================] - 143s 578ms/step - loss: 0.3965 - accuracy: 0.7887 - val_loss: 0.2384 - val_accuracy: 0.9046\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 141s 570ms/step - loss: 0.1201 - accuracy: 0.9572 - val_loss: 0.2510 - val_accuracy: 0.9046\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9909Restoring model weights from the end of the best epoch.\n",
      "247/247 [==============================] - 142s 573ms/step - loss: 0.0298 - accuracy: 0.9909 - val_loss: 0.3914 - val_accuracy: 0.8994\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb28b21c470>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# callbacks\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                      patience=2,\n",
    "                                      restore_best_weights=True,\n",
    "                                      verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, \n",
    "          validation_split=0.1,\n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE,\n",
    "          callbacks=[es], \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuKczZqYpxUk"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "3Zik9CWQgNlK",
    "outputId": "5a8971bc-20ef-4f75-8679-dac7f5fadf37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 6s 14ms/step - loss: 0.2328 - accuracy: 0.9059\n",
      "Accuracy: 90.59%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "B904TLKNiA1B",
    "outputId": "e4b19799-00bd-4f96-8688-9cdff76dda1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-cb5d9830b2ab>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test).ravel()\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "HVjbqjaopxU-",
    "outputId": "119dbbcf-1d47-4a7f-ec3a-38173ca36da3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive']"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = ['positive' if item == 1 else 'negative' for item in predictions]\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "mINpo7mDpxVC",
    "outputId": "646644fe-e736-46be-bf19-503c541dbcaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.91      7490\n",
      "    positive       0.90      0.91      0.91      7510\n",
      "\n",
      "    accuracy                           0.91     15000\n",
      "   macro avg       0.91      0.91      0.91     15000\n",
      "weighted avg       0.91      0.91      0.91     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6751</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>672</td>\n",
       "      <td>6838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative      6751       739\n",
       "positive       672      6838"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "labels = ['negative', 'positive']\n",
    "print(classification_report(test_sentiments, predictions))\n",
    "pd.DataFrame(confusion_matrix(test_sentiments, predictions), index=labels, columns=labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "10-NLP Applications - Text Classification - Deep Learning CNN Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
